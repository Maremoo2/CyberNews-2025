name: Weekly Intelligence Analysis

on:
  schedule:
    # Run every Monday at 00:00 UTC
    - cron: '0 0 * * 1'
  workflow_dispatch:
    # Allow manual triggering

concurrency:
  group: weekly-analysis
  cancel-in-progress: false

permissions:
  contents: write

jobs:
  analyze:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run weekly aggregation
        run: npm run aggregate-weekly
        
      - name: Run AI analysis
        id: ai-analysis
        continue-on-error: true
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: npm run analyze-weekly
      
      - name: Run executive brief
        id: exec-brief
        continue-on-error: true
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: npm run executive-brief
      
      - name: Check for changes and prevent duplicates
        id: git-check
        run: |
          # Get week identifier first
          WEEK_FILE=$(ls -1t public/data/aggregates/week_*.json 2>/dev/null | head -1 || echo "")
          if [ -z "$WEEK_FILE" ]; then
            echo "No aggregate files found"
            echo "changed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          WEEK=$(basename "$WEEK_FILE" .json | sed 's/week_//')
          echo "week=$WEEK" >> $GITHUB_OUTPUT
          
          # Check if this week's files already exist in the repo
          AGGREGATE_EXISTS=$(git ls-files "public/data/aggregates/week_${WEEK}.json" | wc -l)
          ANALYSIS_EXISTS=$(git ls-files "public/data/analysis/week_${WEEK}.json" | wc -l)
          BRIEF_EXISTS=$(git ls-files "public/data/briefs/week_${WEEK}.json" | wc -l)
          
          if [ "$AGGREGATE_EXISTS" -gt 0 ] && [ "${{ steps.ai-analysis.outcome }}" == "success" ] && [ "$ANALYSIS_EXISTS" -gt 0 ] && [ "${{ steps.exec-brief.outcome }}" == "success" ] && [ "$BRIEF_EXISTS" -gt 0 ]; then
            echo "Week $WEEK already processed - skipping commit"
            echo "changed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Stage ONLY the specific files for this week
          git add "public/data/aggregates/week_${WEEK}.json"
          
          FILES_ADDED=""
          if [ "${{ steps.ai-analysis.outcome }}" == "success" ] && [ -f "public/data/analysis/week_${WEEK}.json" ]; then
            git add "public/data/analysis/week_${WEEK}.json"
            FILES_ADDED="${FILES_ADDED}analysis "
          fi
          
          if [ "${{ steps.exec-brief.outcome }}" == "success" ] && [ -f "public/data/briefs/week_${WEEK}.json" ]; then
            git add "public/data/briefs/week_${WEEK}.json"
            FILES_ADDED="${FILES_ADDED}brief "
          fi
          
          if [ -n "$FILES_ADDED" ]; then
            echo "commit_type=with_ai" >> $GITHUB_OUTPUT
            echo "files_added=$FILES_ADDED" >> $GITHUB_OUTPUT
          else
            echo "commit_type=aggregate_only" >> $GITHUB_OUTPUT
          fi
          
          # Check if staged changes exist
          if git diff --staged --quiet; then
            echo "No staged changes"
            echo "changed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "changed=true" >> $GITHUB_OUTPUT
      
      - name: Commit and push analysis results
        if: steps.git-check.outputs.changed == 'true'
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          WEEK="${{ steps.git-check.outputs.week }}"
          COMMIT_TYPE="${{ steps.git-check.outputs.commit_type }}"
          FILES_ADDED="${{ steps.git-check.outputs.files_added }}"
          
          # Files already staged in previous step
          if [ "$COMMIT_TYPE" == "with_ai" ]; then
            COMMIT_MSG="chore: add weekly AI content for week $WEEK ($FILES_ADDED)"
          else
            COMMIT_MSG="chore: add weekly aggregate for week $WEEK (AI processing failed)"
          fi
          
          git commit -m "$COMMIT_MSG"
          
          # Try a few times to push (concurrent writers may conflict)
          for i in 1 2 3 4 5; do
            echo "Attempt $i: fetch + push"
            git fetch origin main
            
            # Try to rebase, but preserve our commit
            if ! git rebase origin/main; then
              echo "Rebase failed. Aborting and retrying with new strategy..."
              git rebase --abort
              
              # Re-commit if needed (in case rebase abort lost the commit)
              if ! git diff-index --quiet HEAD --; then
                git add public/data/aggregates/*.json public/data/analysis/*.json public/data/briefs/*.json
                git commit -m "chore: add weekly AI content for week $WEEK" || true
              fi
              
              echo "Backing off before retry..."
              sleep $((i * 3))
              continue
            fi
            
            if git push origin HEAD:main; then
              echo "Push succeeded"
              exit 0
            fi
            
            echo "Push rejected. Backing off..."
            sleep $((i * 3))
          done
          
          echo "Push failed after retries"
          exit 1
