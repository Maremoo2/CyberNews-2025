name: Weekly Intelligence Analysis

on:
  schedule:
    # Run every Monday at 00:00 UTC
    - cron: '0 0 * * 1'
  workflow_dispatch:
    # Allow manual triggering

concurrency:
  group: weekly-analysis
  cancel-in-progress: false

permissions:
  contents: write

jobs:
  analyze:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run weekly aggregation
        run: npm run aggregate-weekly
        
      - name: Run AI analysis
        id: ai-analysis
        continue-on-error: true
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: npm run analyze-weekly
      
      - name: Run executive brief
        id: exec-brief
        continue-on-error: true
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: npm run executive-brief
      
      - name: Check for changes and prevent duplicates
        id: git-check
        run: |
          # Get week identifier first
          WEEK_FILE=$(ls -1t public/data/aggregates/week_*.json 2>/dev/null | head -1 || echo "")
          if [ -z "$WEEK_FILE" ]; then
            echo "No aggregate files found"
            echo "changed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          WEEK=$(basename "$WEEK_FILE" .json | sed 's/week_//')
          echo "week=$WEEK" >> $GITHUB_OUTPUT
          echo "DEBUG: Processing week $WEEK"
          
          # Fetch latest from remote to ensure we check against the actual remote state
          git fetch origin main || echo "DEBUG: Could not fetch origin/main (may not exist yet)"
          
          # Check if this week's files already exist on the REMOTE main branch
          # Use git ls-tree to check remote branch, with fallback for when remote doesn't exist
          if git rev-parse origin/main >/dev/null 2>&1; then
            AGGREGATE_EXISTS=$(git ls-tree -r origin/main --name-only | grep "public/data/aggregates/week_${WEEK}.json" | wc -l)
            ANALYSIS_EXISTS=$(git ls-tree -r origin/main --name-only | grep "public/data/analysis/week_${WEEK}.json" | wc -l)
            BRIEF_EXISTS=$(git ls-tree -r origin/main --name-only | grep "public/data/briefs/week_${WEEK}.json" | wc -l)
            echo "DEBUG: Remote branch exists. Aggregate=$AGGREGATE_EXISTS, Analysis=$ANALYSIS_EXISTS, Brief=$BRIEF_EXISTS"
          else
            # Remote main doesn't exist yet (first run), so nothing is processed
            AGGREGATE_EXISTS=0
            ANALYSIS_EXISTS=0
            BRIEF_EXISTS=0
            echo "DEBUG: Remote main branch does not exist yet (first run)"
          fi
          
          # Only skip if ALL files exist on remote AND all steps succeeded
          if [ "$AGGREGATE_EXISTS" -gt 0 ] && [ "${{ steps.ai-analysis.outcome }}" == "success" ] && [ "$ANALYSIS_EXISTS" -gt 0 ] && [ "${{ steps.exec-brief.outcome }}" == "success" ] && [ "$BRIEF_EXISTS" -gt 0 ]; then
            echo "Week $WEEK already fully processed on remote - skipping commit"
            echo "changed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "DEBUG: Week $WEEK needs processing (at least one file missing or step failed)"
          
          # Stage ONLY the specific files for this week that need to be added
          FILES_ADDED=""
          
          # Only add aggregate if it doesn't exist on remote
          if [ "$AGGREGATE_EXISTS" -eq 0 ] && [ -f "public/data/aggregates/week_${WEEK}.json" ]; then
            git add "public/data/aggregates/week_${WEEK}.json"
            FILES_ADDED="${FILES_ADDED}aggregate "
            echo "DEBUG: Staging aggregate file"
          fi
          
          # Add analysis if it was generated successfully and doesn't exist on remote
          if [ "${{ steps.ai-analysis.outcome }}" == "success" ] && [ "$ANALYSIS_EXISTS" -eq 0 ] && [ -f "public/data/analysis/week_${WEEK}.json" ]; then
            git add "public/data/analysis/week_${WEEK}.json"
            FILES_ADDED="${FILES_ADDED}analysis "
            echo "DEBUG: Staging analysis file"
          fi
          
          # Add brief if it was generated successfully and doesn't exist on remote
          if [ "${{ steps.exec-brief.outcome }}" == "success" ] && [ "$BRIEF_EXISTS" -eq 0 ] && [ -f "public/data/briefs/week_${WEEK}.json" ]; then
            git add "public/data/briefs/week_${WEEK}.json"
            FILES_ADDED="${FILES_ADDED}brief "
            echo "DEBUG: Staging brief file"
          fi
          
          if [ -z "$FILES_ADDED" ]; then
            echo "DEBUG: No files to stage (all already exist on remote)"
            echo "changed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "DEBUG: Files to commit: $FILES_ADDED"
          
          # Determine commit type based on what was added
          if echo "$FILES_ADDED" | grep -Eq "(analysis|brief)"; then
            echo "commit_type=with_ai" >> $GITHUB_OUTPUT
            echo "files_added=$FILES_ADDED" >> $GITHUB_OUTPUT
          else
            echo "commit_type=aggregate_only" >> $GITHUB_OUTPUT
            echo "files_added=$FILES_ADDED" >> $GITHUB_OUTPUT
          fi
          
          # Check if staged changes exist
          if git diff --staged --quiet; then
            echo "No staged changes"
            echo "changed=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "changed=true" >> $GITHUB_OUTPUT
      
      - name: Commit and push analysis results
        if: steps.git-check.outputs.changed == 'true'
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          WEEK="${{ steps.git-check.outputs.week }}"
          COMMIT_TYPE="${{ steps.git-check.outputs.commit_type }}"
          FILES_ADDED="${{ steps.git-check.outputs.files_added }}"
          
          echo "DEBUG: Committing week $WEEK with type $COMMIT_TYPE"
          echo "DEBUG: Files added: $FILES_ADDED"
          
          # Files already staged in previous step
          if [ "$COMMIT_TYPE" == "with_ai" ]; then
            COMMIT_MSG="chore: add weekly AI content for week $WEEK ($FILES_ADDED)"
          else
            COMMIT_MSG="chore: add weekly aggregate for week $WEEK (AI processing failed)"
          fi
          
          git commit -m "$COMMIT_MSG"
          echo "DEBUG: Commit created successfully"
          
          # Try pushing with rebase retry logic (handle concurrent runs)
          for i in 1 2 3 4 5; do
            echo "DEBUG: Push attempt $i of 5"
            
            # Pull with rebase to integrate any concurrent changes
            if git rev-parse origin/main >/dev/null 2>&1; then
              echo "DEBUG: Pulling latest changes from origin/main"
              if git pull --rebase origin main; then
                echo "DEBUG: Rebase successful"
              else
                echo "DEBUG: Rebase failed, aborting and retrying..."
                git rebase --abort
                sleep $((i * 3))
                continue
              fi
            else
              echo "DEBUG: origin/main does not exist, this is the first push"
            fi
            
            # Try to push
            if git push origin HEAD:main; then
              echo "DEBUG: Push succeeded on attempt $i"
              exit 0
            fi
            
            echo "DEBUG: Push rejected, backing off before retry..."
            sleep $((i * 3))
          done
          
          echo "ERROR: Push failed after 5 attempts"
          exit 1
      
      - name: Trigger deployment
        if: steps.git-check.outputs.changed == 'true'
        run: |
          echo "Triggering deployment workflow"
          gh workflow run deploy.yml --ref main
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
